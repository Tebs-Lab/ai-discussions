# Exercise: Specific RNN and Transformer Architectures

In this exercise you'll be broken into small teams and asked to research well known architectures for certain types of problems.

## The Questions

Answer the following questions for each of the following tasks

* Text Translation
* Document Summarization
* Text Generation
* Time Series Forecasting

1. Can you find the name of an architecture that is current and popular for this task?
    * When was this architecture first used/described?
    * Can you find examples of specific tasks it has had success on? (e.g. generating blogs, future stock price prediction)
    * Are there any key data-preprocessing steps that must be applied?
2. Can you find an image representing this architecture?
3. Try to describe the key features of this architecture...
    * What types of layers are used? (LSTM, Attention... ?)
    * Can you explain why the shapes of each layer might have been chosen?
    * Are there any obvious forms of regularization being applied?
